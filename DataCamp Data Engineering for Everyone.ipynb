{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0bdcd3-e35f-4843-8c1c-499039528d48",
   "metadata": {},
   "source": [
    "## Data Engineering for Everyone\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c32f9e-0048-4ae8-9f75-819068a7e83a",
   "metadata": {},
   "source": [
    "## Course Description\n",
    "\n",
    "In 2019, the average salary for data engineers overtook data scientists. How did this happen? Companies wanting to find the gold within their data realized it wasnâ€™t possible if they hadnâ€™t yet built the mine. Data engineers lay the foundations that make data science possible.\n",
    "\n",
    "In this course, youâ€™ll learn about a data engineerâ€™s core responsibilities, how they differ from data scientists, and facilitate the flow of data through an organization. Through hands-on exercises youâ€™ll follow Spotflix, a fictional music streaming company, to understand how their data engineers collect, clean, and catalog their data. By the end of the course, youâ€™ll understand what your company's data engineers do, be ready to have a conversation with a data engineer, and have a solid foundation to start your own data engineer journey. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ea6e9-9934-497c-8302-ca87e95f88e3",
   "metadata": {},
   "source": [
    "##  What is data engineering?\n",
    "Free\n",
    "0%\n",
    "\n",
    "In this chapter, youâ€™ll learn what data engineering is and why demand for them is increasing. Youâ€™ll then discover where data engineering sits in relation to the data science lifecycle, how data engineers differ from data scientists, and have an introduction to your first complete data pipeline.\n",
    "\n",
    "    Data engineering and big data    50 xp\n",
    "    Go with the flow    100 xp\n",
    "    Not responsible    100 xp\n",
    "    Big time    100 xp\n",
    "    Data engineers vs. data scientists    50 xp\n",
    "    Tell me the truth    50 xp\n",
    "    Who is it    100 xp\n",
    "    The data pipeline    50 xp\n",
    "    It's not true    50 xp\n",
    "    Pipeline    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effdcb5-ffe1-4a5e-9ba3-c36564b7ba57",
   "metadata": {},
   "source": [
    "##  Storing data\n",
    "Free\n",
    "0%\n",
    "\n",
    "Itâ€™s time to talk about data storageâ€”one of the main responsibilities for a data engineer. In this chapter, youâ€™ll learn how data engineers manage different data structures, work in SQLâ€”the programming language of choice for querying and storing data, and implement appropriate data storage solutions with data lakes and data warehouses.\n",
    "\n",
    "    Data structures    50 xp\n",
    "    Structures    50 xp\n",
    "    What's the difference    100 xp\n",
    "    SQL databases    50 xp\n",
    "    We can work it out    50 xp\n",
    "    Columns    50 xp\n",
    "    Different breeds    100 xp\n",
    "    Data warehouses and data lakes    50 xp\n",
    "    Tell the truth    50 xp\n",
    "    Our warehouse (in the middle of our street)    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fd570-3fc5-4ae0-86fc-caa6b0dfa5e5",
   "metadata": {},
   "source": [
    "##  Moving and processing data\n",
    "Free\n",
    "0%\n",
    "\n",
    "Data engineers make life easy for data scientists by preparing raw data for analysis using different processing techniques at different steps. These steps need to be combined to create pipelines, which is when automation comes into play. Finally, data engineers use parallel and cloud computing to keep pipelines flowing smoothly.\n",
    "\n",
    "    Processing data    50 xp\n",
    "    Connect the dots    100 xp\n",
    "    Scheduling data    50 xp\n",
    "    Schedules    100 xp\n",
    "    One or the other    100 xp\n",
    "    Parallel computing    50 xp\n",
    "    Whenever, whenever    50 xp\n",
    "    Parallel universe    100 xp\n",
    "    Cloud computing    50 xp\n",
    "    Obscured by clouds    100 xp\n",
    "    Somewhere I belong    100 xp\n",
    "    We are the champions    50 xp \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d10a95-a89a-4124-a4a3-af3d10575bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c890bd7d-d81c-40d9-9ad3-4238b88aea62",
   "metadata": {},
   "source": [
    "## Data engineering and big data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Welcome to Data Engineering for everyone.  My name is Hadrien, and I will be your instructor for this course.  This is a conceptual course; there is no code involved.  \n",
    "\n",
    "If you are not a developer, the objective is to provide you with a solid enough understanding of the topic so that you can exchange with and understand data engineering team.  If you are interested in actually developing data engineering projects, the objective is to equip you with conceptual knowledge allowing you to get the most out of our data engineering curriculum.  \n",
    "\n",
    "This first chapter will clarify what Data Engineering is; specifically, how it relates to big data and how a data engineer differ from a data scientist.  Data Engineers build data pipelines, so we will end this chapter by looking into these as well.  \n",
    "\n",
    "Building on these foundations, in the second chapter, we will then take things in order.  We will study data storage: the different types of data structures, the central role that the SQL langurage plays in data engineering, and some storage solutions.  \n",
    "\n",
    "Once data is stored, it is ready to be processed.  This will be the topic of the third chapter, where we will dive deeper into processing methods and tools, scheduling, parallel computing and cloud computing.  \n",
    "\n",
    "\n",
    "Throughout the course, we will look at how all these data engineering concepts are implemented at a fictional music streaming company named Spotflix.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Lets take things from the start then.  There are 4 general steps through which data flows within an organization.  First, we collect and ingest the data, from web traffic, surveys, or media consumption for example.  Data is stored in raw format.  The next step is to prepare it, whcih includes \"cleaning data\", for instance finding missing or duplicate values, and converting data into a more organized format.  Once the data is clean and organized, it can be exploited.  We explore it, visualize it, build dashboards to track changes or compare two set of data.  Finally, once we have a good grasp of our data, we're ready to run experiments, like evaluate which article title gets the most hits, or to build predictive models, for example to forcast stock prices.  \n",
    "# *******************************************************************************************************************\n",
    "\n",
    "[Data Collection & Storage ---> Data Preparation ---> Exploration & Visualization ---> Experimentation & Prediction]\n",
    "\n",
    "# Data engineers are responsible for the first step of the process: \n",
    "ingesting collected data and storing it.  They have a great responsibility as they lay the ground work for data analysts, data scientist and machine learning engineers.  If the data is scattered around, corrupted, and diffcult to access, there is not much to prepare, explore, or experiment with.  And thats exactly why you need a Data Engineer: their job is to deliver the correct data, in the right form, to the right people, as efficiently as possible.  They ingest data from different sources, optimize the databases for analysis, and manage data corruption.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Data engineers develop, construct, test, and maintain architectures such as databases and large-scale processing systems to process and handle massive amounts of data.  If you are not sure what this all means, thats okay.  The course will unpackll this jargon and explain the what, why and how.  \n",
    "\n",
    "With the advent of big data, the demand for data engineers has increased.  Big data can be defined as data so large you have to think about how to deal with its size, because its difficult to process using traditional data management methods.  The graph helps make sense of the growth of big data.  In order of volume, big data is mainly composed of sensors and devices data, social media data, enterprise data and VoIP data.  \n",
    "\n",
    "Big data is commonly characterized by 5 Vs.  [Volume] (the quantity of data points), [Variety] (type and nature of the data: text, image, video, audio), [Velocity] (how fast the data is generated and processed), [Veracity] (how trustworthy the sources are), and [Value] (how actionable the data is).  Data engineers need to take all of this into consideration.  \n",
    "\n",
    "\n",
    "Already, Now you not only know what's waiting for you in this course, but also how data flows with in an organization, when a data engineer intervenes, what their responsibilities are, and how they relate to big data.  Lets check your understanding.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e2f25-c087-4988-94e6-65c60d71c3fe",
   "metadata": {},
   "source": [
    "## Go with the flow\n",
    "\n",
    "To understand what data engineers do, why they are necessary and the impact they have, you need to know how data flows through an organization.\n",
    "\n",
    "Can you order the four steps of the data science workflow chronologically?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Order the steps on chronologically (the step happening first should be at the top and the step happening last at the bottom)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae10c7-2275-4162-af10-bbc372bc6244",
   "metadata": {},
   "source": [
    "Data collection and storage\n",
    "\n",
    "Data preparation\n",
    "\n",
    "Exploration and visualization\n",
    "\n",
    "Experimentation and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628aaa19-ab42-4240-acdc-831372351d40",
   "metadata": {},
   "source": [
    "## Not responsible\n",
    "\n",
    "You recently joined the data science team as a manager for a music streaming company named Spotflix. It's a music platform that lets users stream songs, create playlists, follow artists, watch music videos and even look up lyrics!\n",
    "\n",
    "One of your colleagues just walked to your desk. They just got hired, but they already know you're on the data team - after training with DataCamp, you've made a name for yourself pretty quick! They have a bunch of data tasks they need completed, and they want to make sure they ask the right person. You tell them you can help them identify what they should request from data engineers, and what they should not.\n",
    "\n",
    "Can you deliver on this promise?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Here are several tasks related to working with data. Classify them in two buckets: one for data engineering tasks, one for tasks that are not the responsibility of data engineers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df334fa-d0ec-4d30-8fc7-c5e1db05fb22",
   "metadata": {},
   "source": [
    "Data engineering tasks:\n",
    "    Ensuring corrupte, unreadable music tracks are removed and dont end up facing customers\n",
    "    Optimizing the customers databases for analysis\n",
    "    Gathering music consumption data from desktop and mobile sources\n",
    "    \n",
    "    \n",
    "Not data engineering tasks:\n",
    "    Running an experiment to identify the optimal search bar positioning in the app\n",
    "    Building a visualization to understand listening patterns by city\n",
    "    Based on their listening behavior, predict which songs customers are likely to enjoy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c4818-de2e-42cd-a87d-9bf60e17b671",
   "metadata": {},
   "source": [
    "## Big time\n",
    "\n",
    "You saw how the advent of big data increased the demand for data engineers. As more data gets generated, at a higher rate, with a growing variety of formats, the need for people able to manage this data is soaring.\n",
    "\n",
    "Which of the following statements are true, and which are false?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the statements as either true of false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e894ad-f094-4696-8ce1-1f2af0ab0de5",
   "metadata": {},
   "source": [
    "True:\n",
    "    Value refers to how actionable the data is\n",
    "    Data types refer to the variety of data\n",
    "    \n",
    "    \n",
    "False:\n",
    "    Veracity refers to how frequently the datais generated\n",
    "    Velocity refers to how big the data is\n",
    "    Valume has to do with how trustworthy the data is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24eaac-4a8d-4140-984c-e90413bd9612",
   "metadata": {},
   "source": [
    "## Data engineers vs. data scientists\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great job on these exercises.  In the previous lesson we got acquainted with how the data flows through an organization, focusedon the data engineers's responsibilities, and quickly mentioned data scientists.  \n",
    "\n",
    "|Data Engineer ----------|      |Data Scientist -------------------------------------------------------------------|\n",
    "[Data Collection & Storage ---> Data Preparation ---> Exploration & Visualization ---> Experimentation & Prediction]\n",
    "\n",
    "To prevent the confusion and assumptions that comes with buzzwords, lets clarify how data engineers and data scientists contrast and compare.  You already know that [data engineers] focus on the first part of the workflow.  Their role is to ingest and store the data so its easily accessible and ready to be analyzed.  [Data scientist] intervene on the rest of the workflow: they prepare the data according to their analysis needs, explore it, build insightful visualizations, and then run experiments or build predictive models.  Data engineers lay the groundwork that makes data science activity possible.  Lets see how data engineers enable data scientists.  \n",
    "\n",
    "Vivian is a [data engineer] at Spotflix, our music streaming company, and Julian is a [data scientist].  Data engineers ingest and store collected data, so that data scientist can exploit it.  \n",
    "# *******************************************************************************************************************\n",
    "Data engineers ensure that databases are optimizaed for analysis (correct table structure, information easy to retrieve) while data scientists access the databases to exploit the data it contains.  At Spotflix, Vivian makes sure that Julian can easily access tracks, artist, listening sessions data, and can analyze it without too much preparation work.  Data engineers build data pipelines.  The next lesson is focused on this topic.  Data scientist use the pipelines' outputs.  At Spotflix, Vivian builds the pipeline that pulls listening sessions data, so that Julian's analyses remain up to date.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Based on above, it's no surprise that [data engineers are software experts, while data scientists are analytics experts].  In general, Vivian uses the languages like software-oriented Python or Java, and SQL to create, update and transform databases, while Julian uses the analytics-oriented Python or R, and SQL to query or in other words, request information from databases.  \n",
    "\n",
    "\n",
    "\n",
    "Now you understand at which stages data engineers and data scientists intervene, and how data engineers enable data scientists.  Time for a sanity check.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8d8dc-9ba0-4f73-b00c-0277d5c2db7c",
   "metadata": {},
   "source": [
    "## Tell me the truth\n",
    "\n",
    "In 2012, IBM declared that 90% of the data in the world had been created in the past 2 years. That same year, the amount of digital data in the world first exceeded 1 zetabyte (1 billion terabytes). In 2020, we're expected to reach 44 zetabytes. This big data era led to the advent of two new roles: data engineers and data scientists. You just studied the differences between these two roles.\n",
    "\n",
    "Let's have a quick sanity check: which of the following options is true?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    Data engineers intervene at the very end of the data workflow.\n",
    "    1\n",
    "    Data scientists build pipelines.\n",
    "    2\n",
    "    Data engineers need strong statistical expertise.\n",
    "    3\n",
    "#    Data engineers enable data scientists.\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320f38b-035f-439f-97cf-acf84b759610",
   "metadata": {},
   "source": [
    "## Who is it\n",
    "\n",
    "In the first lesson, you classified some data related tasks between data engineer tasks and not data engineer tasks. Let's raise the bar and see if you can assign more specific tasks to data engineers or data scientists.\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Assign the tasks to the data engineer or the data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc077e5a-6fc1-4c73-8d9c-7e2ffaaef127",
   "metadata": {},
   "source": [
    "Data engineer:\n",
    "    Ensure that people who use the databases can't erase music videos by mistake\n",
    "    Use Java to build a pipeline collecting album covers and storing them\n",
    "    Provide listening sessions data so it can be analyzed with minimal preparation work\n",
    "    \n",
    "    \n",
    "Data scientist:\n",
    "    Identify which customers are likely to end their Spotflix subscriptions, so marketing can target them and encourage them to renew\n",
    "    Use Python to run an analysis on wheather users prefex having the search bar on the top left or the top right of the Spotflix desktopapp\n",
    "    Find out in which countries certain artists are popular to give them insights on where to tour\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189404-7881-48c5-9a28-376408ccdb94",
   "metadata": {},
   "source": [
    "## The data pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Alright, we've mentioned the term pipeline several times by now, so lets focus on it for this lesson.  You may have heard the [data is new oil], as first coined by the economist, so lets follow this idea.  We extract crude oil from an oil field.  We moved the crude oil to a distillation unit, where we separate the oil into several products.  Some products are sent directly to their final users.  For example, some pipes go straight to airports to deliver kerosene.  Other products, like gasoline, are sent to gas storage facilities and stored in big tanks, before being distributed to gas stations.  Other products, like naphtha, go through several chemical transformations to create synthetic polymers for example.  Manufactures use synthetic polymers to create new products, like CDs.  \n",
    "\n",
    "As you can see, we have many pipelines trying it all together.  CDs, Ss last century, Vivian thinks.  However, to manager data for Spotflix, she follows a procedure similar to oil processing.  Companies ingest data from many different sources, which needs to be processed and stored in various ways.  To handle that, we need [data pipelines] that efficiently automate the flow from one station to the next, so that data scientists can use up-to-date, accurate, relevant data.  This isn't a simple task and thats's why data engineers are so important.  \n",
    "\n",
    "At Spotflix, we have sources from which we extract data.  For example, the users' actions and listening history on the mobile Spotflix app and desktop Spotflix app, and the Spotflix website itself.  We also have website Spotflix uses internally, like their HR management system for payroll and benefits.  The data is ingested into Spotflix system, moving from their respective sources to our data lake (no fear, we will talk about data lakes in the next chapter).  These are our first three pipelines.  \n",
    "\n",
    "We then organize the data, moving it into databases (we will talk more about databases in chapter 2 as well).  It could be [artist data], like name, number of followers, and associated acts, [albums data], like label, producer, year of release, [tracks data], like name, length, featured artists, and number of listens, [playlists data], like name, song it contains, and date of creation, [customer data], like username, account opening date, subscription tier, or [employees data], like name, salary, reporting manager, updated by human resources.  These are 6 new pipelines.  \n",
    "\n",
    "Some albums data can be extracted and stored directly.  For example, album cover pictures all have the same format, so we can store them directly without having to crop them.  That is one more pipeline.  \n",
    "\n",
    "Employees could be split in different tables by department, for example, sales, engineering, support, etc. (we will talk about tables in chapter 2 as well).  For now, that's 3 more pipelines.  These tables could be further split by offices, for example, US, Belgium, and UK.  If data scientists has to analyze employee data (to investigate employee turnover for example), this is the data they would use.  And three is anothet 3 more pipelines for each department.  \n",
    "\n",
    "Tracks would need to be processed, first to check if the track is readable, then to check if the corresponding artist is in the database, to make sure the file is in the correct size and format, etc.  Thats 1 more pipeline, that we will unpack into chapter 3 when we will talk about ata processing.  The data can then be stored in a new, clean tracks database.  this is one of the databases data scientists could use to build a recommendation engine by analyzing songs for similarity, for example.  And thats our last pipeline.  \n",
    "\n",
    "\n",
    "\n",
    "Phone app  \\                employees -- (sales dept, engineering dept, support dept) -- (US, UK, B)\n",
    "                            customers\n",
    "                            playlists\n",
    "Desktop app -- Data lake -- tracks    -- -- -- -- \n",
    "                            albums    -- album pictures\n",
    "                            artists\n",
    "Website    /\n",
    "\n",
    "\n",
    "In a nutshell, data pipelines ensures the data flows efficiently through the organization.  They automate extracting, transforming, combining, validating, and loading data, to reduce human intervention and errors, and decrease the time it takes for data to flow through the organization.  Dont worray, we'll cover this in detail in the last chapter.  One term you will hear a lot is [ETL].  Its a popular framework for designing data pipelines.  It breaks the flow of data into 3 sequential steps: first [Extracting data], then [Tranforming data], and finally [Loading to new database].  The key here is that data processed before its stored.  In general, data pipelines move data from one systemto another.  They may follow ETL, but not all the time.  For instance, the data may not be transformed, and routed directly to applications like visualization tools or Salesforce.  \n",
    "\n",
    "\n",
    "\n",
    "Okay, now you understand  a data pipeline is, what its used for, why its important, how we use them at Spotflix, and hwere ETL fits in.  Lets solidify your understanding of data pipelines with a couple exercises, and then onwards to chapter 2 to dive into the details of data storage.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22c749-9f9a-4a5d-b79b-5602ea2e01d8",
   "metadata": {},
   "source": [
    "## It's not true\n",
    "\n",
    "The main objective, when setting up data pipelines, is to improve the efficiency with which data flows, from its ingestion to the final users.\n",
    "\n",
    "Most of the options below are true, but one is false. Which one is it?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    Data pipelines ensure an efficient flow of the data through the organization.\n",
    "    1\n",
    "    Data pipelines automate data extraction.\n",
    "    2\n",
    "#    Data pipelines necessarily include a transformation step.\n",
    "    3\n",
    "    ETL stands for Extract, Transform, Load.\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4be68-dd39-43c8-b8a3-7fc268f18ce8",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Once you've successfully completed this exercise, make sure to read the success message! ðŸŽ¶ðŸ˜‰\n",
    "\n",
    "You've just seen some examples of pipelines used at Spotflix. Let's have you build one!\n",
    "\n",
    "Our data engineer, Vivian, is working on building new pipelines to generate a new product: the Weekly Playlist. It's a playlist that is created by our system every day to recommend new songs that users might like based on their tastes.\n",
    "\n",
    "In this exercise, you will find some steps. Can you order the steps correctly to help her build the pipeline generating a Weekly Playlist for each user? Let's start with one user, and build a pipeline to generate a Weekly Playlist for Julian, our data scientist.\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Order the steps chronologically (the step happening first should be at the top and the step happening last at the bottom).\n",
    "\n",
    "Hint\n",
    "\n",
    "    You need to know Julian's tastes before anything.\n",
    "    You then need to find users with similar tastes.\n",
    "    Once this is done, you can find the songs these users listen to that Julian might like.\n",
    "    You need to load these songs in a table: that will be the playlist we will recommend to Julian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47a1f6-5463-423a-8f55-9ea94be814bb",
   "metadata": {},
   "source": [
    "Extract the songs Julian listened to the most over the past month\n",
    "\n",
    "Find other users who listened to these same songs a lot as well\n",
    "\n",
    "    Extract only songs these other users listen to that are of the same genre as the ones in Julia's listening session.  There are our recommendations\n",
    "    ||\n",
    "    Load only the 10 top songs these users listened to the most over the past week into a table called \"Similar profiles\"\n",
    "\n",
    "Load the recommended songs into a new table.  Thats Julian's weekly playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da43b857-c009-45cc-817c-00a0459f57c3",
   "metadata": {},
   "source": [
    "## Data structures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Awesome job on chapter 1.  Lets continue our exploration of the world of data engineering.  This second chapter will focus on storage.  In this lesson, we're going to learn more about data structure.  Structured data is easy to search and organize.  Data is entered following a rigid structure, like a spreadsheet where there are set columns.  Each column takes values of a certain type, like text, data, or decimal.  It makes it easy to form relations, hence its organized in what is called a relational database.  About 20% of the data is structured.  SQL which stands for Structured Query Langurage, is used to query such data.  \n",
    "\n",
    "Here is an example of structured data. (slide shows a DF table).  This is an extract of Spotflix's employee table (index, last_name, first_name, role, team, full_time, office).  Its easy to read the table and well-organized.  You can see it follows a model: each row expects an employee and each column a specific information about that employee.  Each column needs to be of a certain type.  The index is a number, and acts as a unique ID, becuase 2 employee may have the same name, role and office.  The penultimate column holds logical values: values can only be true or false.  For example,  Rick Sanchez is part-time.  The rest of the columns are text.  \n",
    "\n",
    "Because its [structured] we can easily relate this table to other structured data.  For example, if there is another table holding information about offices, we can connect on the office column.  Tables that can be connected that way from a [relational database].  [Semi-structured data] resembles structured data, but allows more freedom.  Its therefore relatively easy to organize, and pretty structured, but allows more flexibility.  It also has different types and can be grouped to form relations, although this is not as straightforward as with structured data - you have to pay for that flexibility at some point.  \n",
    "\n",
    "Semi-structured data is stored in NoSQL databases (as opposed to SQL) and usually leverages the JSON, XML or YAML file formats.  Below is an example of a JSON file storing favorite artists of each Spotflix user.  As you can see, the model is consistent: each user id contains the user's last name and first name, and their favorite artists.  However, the number of favorite artists may differ: I have 4, Sara has 2 and Lis has 3 favorite artists.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Relational databases dont allow that kind of flexibility, but semi-structured formats let you do it.  Unstructed data is the data that does not follow a model and can't be contained in a rows and columns format.  This makes it difficult to search and organize.  Its usually text, sounds, pictures or video.  Its usually stored in data lakes, althoughit can also appear in data warehouses or databases - don't worry, we will cover the difference between these at the end of this chapter.  \n",
    "\n",
    "\n",
    "{\n",
    "{\"user_1645156\": {\n",
    "    \"last_name\": \"Lacroix\", \n",
    "    \"first_name\": \"Hadrien\", \n",
    "    \"favorite_artists\": [\"Fools in Deed\", \"Gojira\", \"Pain\", \"Nanowar of Stell\"]}\n",
    "    },\n",
    "{\"user_5913764\": {\n",
    "    \"last_name\": \"Billen\", \n",
    "    \"first_name\": \"Sara\", \n",
    "    \"favorite_artists\": [\"Tamino\", \"Taylor Swift\"]}\n",
    "    }, \n",
    "    ......\n",
    "}\n",
    "\n",
    "\n",
    "# Most of the data around us is unstructed.  \n",
    "Unstructed data can be extremely valuable, but because its hard to search and organize, this value could not be extracted untill recently, with the advent of machine learning and artificial intelligence.  At Spotflix, unstructed data consists in lyrics, songs, albums picture and artists profile pictures, and music videos.  At Spotflix, we could use machine learning algorithms to parse song spectrums, analyze beats per minutes, chord progressions, genres to help categorize songs.  Or, we could have artists give additional informati when they upload their songs.  Having them add the genre, and some tags, would make it semi-structured data, and would make searching and organizing easier.  \n",
    "\n",
    "\n",
    "Alright, now you know what is characteristic of [structured data], [semi-structured data] and [unstructured data], the difference between the 3, and you're able to give examples for each of them.  Lets consolidate this knowlege with some exercises.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c302b-2d21-479d-929f-9460854580f3",
   "metadata": {},
   "source": [
    "## Structures\n",
    "\n",
    "In the video, you learned about the three different types of data structure. The less structured the data, the more flexibility there is in how it's stored.\n",
    "\n",
    "Which of the following statements is false?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    Structured data is easier to search because values are separated and organized into columns.\n",
    "    1\n",
    "    Semi-structured data allows some flexibility that structured data doesn't: different observations have different sizes.\n",
    "    2\n",
    "#    Structured data makes it harder to draw relationships with other data tables.\n",
    "    3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562839f-b21f-423f-a293-0d57d05974e9",
   "metadata": {},
   "source": [
    "## What's the difference\n",
    "\n",
    "You've just learned that data can exist in different structures. Can you correctly define structured, semi-structured and unstructured data?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the statements to the data structure they correspond to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59ee33-0660-4e0c-9d3b-7b3f96f53dee",
   "metadata": {},
   "source": [
    "Structured:\n",
    "    Is easy to search and organize\n",
    "    Is created and queried using SQL\n",
    "    Corresponds to data in tabular cormat\n",
    "    \n",
    "Semi-structured:\n",
    "    Follows a model while allowing more flexibility than structured data\n",
    "    Is moderately easy to search and organize\n",
    "    Is stored in XML or JSON format, or in NoSQL databases\n",
    "    \n",
    "Unstructured:\n",
    "    Is usually stored in data lake\n",
    "    Is difficult to search and organize\n",
    "    Stores images, pictures, videos and text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168ba0b-2528-4131-86e3-51c5dd3391be",
   "metadata": {},
   "source": [
    "## SQL databases\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great job on these exercises.  Lets pursue.  We've mentioned SQL several times by now, so how about we spend a bit more time on this langurage that is so fundamental in data engineering.  \n",
    "\n",
    "SQL stands for Structured Query Language.  SQL is to databases what English is to pop music.  Its the preferred langurage to query RDBMS or Relational Database Management System - sically systems that gather several tabels like Employee table from the previous lesson, where all tables are related to each other.  More on that in a moment.  \n",
    "\n",
    "SQL has 2 main advantagesL it allows you to access many records at once, and group, filter or aggregate them.  Most programming langurage let you do that, but SQL was the first, which is why its been so influential.  Its a little bit like the Beatles and pop music.  Its also very close to English, which makes it easy to write and understand.  As you already know data engineers use SQL to create maintain databases, while data scientists use SQL to query databases.  We're not going to learn SQL in this course, not test you on it: we have great courses and tracks that covers this topic.  However, looking at some examples will help you understanding.  \n",
    "\n",
    "# Lets look at a data engineering example first, creating a table.  \n",
    "Take a moment to refresh your memory of Spotflix exmplyee table.  Remember the first column holds non-decimal numbers, the penultimate one store logic value, and the others hold text.  We can create such a table using SQL.  We type the command [CREAT TABEL], and declare the name of the table, \"employees\", then we proceed to create the first column, employee_id, and specify the type of data expected, integers - means this columns will only accept whole numbers, without any decimal.  We then create second column, first_name, and specify it should be text (VARCHAR stands for \"variable characters\").  255 here means that the value entered can't be more than 255 characters long.  And we do the same for last_name, role, and team.  We declare full_time as a Boolean, which is the type for logical values.  this column can only holds 0 or 1.  Then office is declared as VARCHAR as well because its text.  Data engineers then run other statements to update the table and write records into it.  \n",
    "\n",
    "\n",
    "[\n",
    "CREATE TABEL employees (\n",
    "    employee_id INT, \n",
    "    first_name VARCHAR(255), \n",
    "    last_name VARCHAR(255), \n",
    "    role VARCHAR(255), \n",
    "    team VARCHAR(255), \n",
    "    full_time BOOLEAN, \n",
    "    office VARCHAR(255)\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "Data scientists will then use SQL to query the table.  For example, if Julian wants t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1df77-e0b6-4680-87cd-a2afd967a079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae2e0f-77f1-4d56-a7a0-95748945eb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbc1e8-499f-4d81-beb7-c4618d90ce83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6049a2-d237-4552-aae4-9c0283ee7f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27138239-e7a8-4f19-819f-995e9072f08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7160d5-53c2-4fe9-9d08-5d50bc27beb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de816026-3757-4abb-87f5-1971d883ce60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e05b0-309f-49cf-8455-12943b6a23b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32faf4-39e0-437d-8147-f0ec8b7ae9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81a997-e2c2-47c0-9b84-4b8a0fc2c30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be14951-2cc5-47e7-b805-d5e0ce80f4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ee394-0433-4a1f-93a2-0d0ab3ee46da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca9c3b-864d-447b-81e7-5bd749d30fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
